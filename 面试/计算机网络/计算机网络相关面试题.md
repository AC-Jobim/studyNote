

![在这里插入图片描述](https://img-blog.csdnimg.cn/2021031521014611.png)



# 一、计算机网络的体系结构

计算机网络体系结构分为3种：OSI体系结构（七层），TCP/IP体系结构（四层），五层体系结构。

![image-20210920103309796](https://gitee.com/jobim/blogimage/raw/master/img/20210920103309.png)



**<font color='blue'>五层协议：</font>**

- **应用层** ：主要任务**通过进程间的交互完成特定网络应用**

  对于不同的网络应用需要有不同的应用层协议，在互联网中的应用层协议很多，如域名系统DNS，支持万维网应用的HTTP协议，支持电子邮件的SMTP协议等等

- **传输层** ：它负责为两台主机中的进程提供通信服务。该层主要有以下两种协议：

  - 传输控制协议 (Transmission Control Protocol，TCP)：提供面向连接的、可靠的数据传输服务，数据传输的基本单位是报文段（segment）；
  - 用户数据报协议 (User Datagram Protocol，UDP)：提供无连接的、尽最大努力的数据传输服务，但不保证数据传输的可靠性，数据传输的基本单位是用户数据报。

- **网络层** ：网络层负责为分组网络中的不同主机提供通信服务，并通过选择合适的路由将数据传递到目标主机。在TCP/IP体系中，由于网络层使用IP协议，因此分组也叫`IP数据报`

- **数据链路层** ：数据链路层通常简称为`链路层`。数据链路层在两个相邻节点传输数据时，将网络层交下来的IP数据报`组装成帧`，在两个相邻节点之间的链路上传送`帧`。

- **物理层** ：保证数据可以在各种物理媒介上进行传输，为数据的传输提供可靠的环境

**<font color='blue'>OSI体系结构：</font>**

多了表示层和会话层：

- **表示层** ：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。
- **会话层** ：建立及管理会话。

**<font color='blue'>TCP/IP体系结构：</font>**

只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。



# 二、应用层



## DNS协议



## Http协议和Https协议

### Http协议协议

* **HTTP是一个基于TCP/IP通信协议来传递数据的协议。实现可靠性的传输文字、图片、音频、视频等超文本数据的规范，格式简称为“超文本传输协议”。**
* 在互联网世界里，HTTP 通常跑在 TCP/IP 协议栈之上，依靠 IP 协议实现寻址和路由、TCP协议实现可靠数据传输、DNS 协议实现域名查找、SSL/TLS 协议实现安全通信。此外，还有一些协议依赖于 HTTP，例如 WebSocket、HTTPDNS 等。这些协议相互交织，构成了一个协议网，而 HTTP 则处于中心地位。



<font color='blue' size='4'>**http报文结构？**</font>

* **`HTTP请求报文`由四个部分组成：请求行、请求头部、空行、请求体。**

  ```
  POST /user HTTP/1.1      //请求行
  Host: www.user.com
  Content-Type: application/x-www-form-urlencoded
  Connection: Keep-Alive
  User-agent: Mozilla/5.0.      //以上是首部行
  （此处必须有一空行）  //空行分割header和请求内容 
  name=world   请求体
  ```

  * **请求行：**由**请求方法、URL字段和HTTP协议版本**3个字段组成
  * **请求头部：**请求头部由关键字/值对组成，每行一对
    1. User-Agent : 产生请求的浏览器类型
    
    2. **Accept** : 客户端希望接受的数据类型，比如 Accept：text/xml（application/json）表示希望接受到的是xml（json）类型
    
    3. **Content-Type**：发送端发送的实体数据的数据类型。
       比如，Content-Type：text/html（application/json）表示发送的是html类型。
       
    4. Host : 请求的主机名，允许多个域名同处一个IP地址，即虚拟主机
    
    5. Content-Length：表示请求消息正文的长度、
    
    6. Accept-Encoding：浏览器能够进行解码的数据编码方式，比如gzip。Servlet能够向支持gzip的浏览器返回经gzip编码的HTML页面
    
    7. Connection：告诉服务器请求链接如何处理
    
       keey-alive表示告诉服务器回传数据后不要马上关闭，保持一小段的链接
    
       closed表示马上关闭
  * **空行**：它的作用是通过一个空行，告诉服务器请求头部到此为止。
  * **请求体：**若方法字段是GET，则此项为空，没有数据。若方法字段是POST,则通常来说此处放置的就是要提交的数据。

* **`HTTP响应报文`也由三部分组成：响应行、响应头、空行、响应体**
  * **响应行：**响应行一般由协议版本、状态码及其描述组成。比如 HTTP/1.1 200 OK。
  
  * **响应头：**
  
    和浏览器缓存有关的字段：[浏览器缓存机制](https://www.cnblogs.com/skynet/archive/2012/11/28/2792503.html)



<font color='blue' size='4'>**HTTP状态码有哪几类？常见的状态码有哪些？**</font>

[![img](https://img2020.cnblogs.com/blog/1993240/202008/1993240-20200811095807426-266630481.png)](https://img2020.cnblogs.com/blog/1993240/202008/1993240-20200811095807426-266630481.png)

200：请求成功状态码。

301：永久重定向。该资源已经分配了新的 URI，服务器返回301响应时，会自动将请求者转移到新URI。

302：临时重定向。表示请求的资源临时分配了新的 URI，希望用户（本次）能使用新的 URI 访问。

401：请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。

404：服务器找不到目标资源。

500：服务器内部出错，无法完成请求。



**<font color='blue'>HTTP协议的8种请求类型</font>**

* GET：向特定的资源发出请求。 
* POST：向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的创建和/或已有资源的修改。 
* PUT：向指定资源位置上传其最新内容。 
* DELETE：请求服务器删除Request-URI所标识的资源。 
* OPTIONS：返回服务器针对特定资源所支持的HTTP请求方法。也可以利用向Web服务器发送'*'的请求来测试服务器的功能性。 
* HEAD：向服务器索要与GET请求相一致的响应，只不过响应体将不会被返回。这一方法可以在不必传输整个响应内容的情况下，就可以获取包含在响应消息头中的元信息。 
* TRACE：回显服务器到的请求，主要用于测试或诊断。 
* CONNECT：HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。



### Https协议





<font color='blue' size='4'>**HTTP和HTTPS的区别？**</font>

1. 安全性不同，http是超文本传输协议，信息是明文传输，https指http over SSL/TLS是具有安全性的ssl加密传输协议
2. http不需认证，而https需要经过CA认证
3. 端口号不同，http的端口号是80，https的端口号是443
4. 连接方式不同，HTTP的连接很简单，是无状态的；HTTPS 协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。





### 一次完整的HTTP请求步骤?

1. DNS查询，依次通过浏览器缓存，OS hosts缓存，路由器缓存，ISP缓存去查询对应的ip。如果有就返回，否则本地DNS服务器会请求根域名服务器获得顶级域名服务器ip，然后向顶级域名服务器请求返回得到权威域名服务器ip，再向权威域名服务器请求得到url->ip的映射返回给本地DNS服务器，本地DNS服务器将ip返回给操作系统并做缓存。
2. 浏览器将请求封装为HTTP报文，在client和server建立连接之前，会进行TCP三次握手
3. 之后将报文从外到里封装为 以太网首部+ip首部+tcp首部+http首部经过网关和路由器发送给server
4. 对于淘宝来说，请求会先到nginx服务器上，然后nginx采用默认的轮询算法进行负载均衡，携带原来browser的ip把报文发送给tomcat
5. tomcat接收到请求之后会解析请求行，请求体，请求头，然后Controller接收请求，交给service处理，之后在访问DB，之后返回，其中不排除redis缓存
6. 浏览器接收response，并进行缓存和解码
7. 浏览器渲染页面





## 跨域请求问题



<font color='blue' size='4'>**为什么会出现跨域问题？**</font>

* 出于浏览器的**同源策略限制**。同源策略（Sameoriginpolicy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。
* 同源策略会阻止一个域的javascript脚本和另外一个域的内容进行交互。**所谓同源（即指在同一个域）就是两个页面具有相同的协议（protocol），主机（host）和端口号（port）**



<font color='blue' size='4'>**跨域解决方法**</font>

* **CORS**

  > [跨域资源共享 CORS 详解](http://www.ruanyifeng.com/blog/2016/04/cors.html)

  跨源资源共享 **Cross-Origin Resource Sharing(CORS)** 是一个新的 W3C 标准，它新增的一组HTTP首部字段（在头信息之中，增加一个`Origin`字段），允许服务端其声明哪些源站有权限访问哪些资源。换言之，它允许浏览器向声明了 CORS 的跨域服务器，发出 XMLHttpReuest 请求，从而克服 Ajax 只能同源使用的限制。另外，规范也要求对于非简单请求，浏览器必须首先使用 OPTIONS方法发起一个预检请求(preflight request)，从而获知服务端是否允许该跨域请求，在服务器确定允许后，才发起实际的HTTP请求

  CORS需要浏览器和服务器同时支持。整个CORS通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS通信与同源的AJAX通信没有差别，代码完全一样。浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。

  ```java
  @RequestMapping("/hello")
  //@CrossOrigin(origins = {"http://127.0.0.1:8080"}),SpringBoot的方式
  public String handle01(HttpServletResponse response) {
      System.out.println("服务器被访问了");
      response.addHeader("Access-Control-Allow-Origin",
                         "http://127.0.0.1:8080");
  
      return "Hello,Spring Boot";
  }
  ```

* **JSONP**

  JSONP 是一种非官方的跨域数据交互协议

  JSONP 本质上是利用 `<script><img><iframe>` 等标签不受同源策略限制，可以从不同域加载并执行资源的特性，来实现数据跨域传输。

  JSONP由两部分组成：回调函数和数据。回调函数是当响应到来时应该在页面中调用的函数，而数据就是传入回调函数中的JSON数据。

  JSONP 的理念就是，与服务端约定好一个回调函数名，服务端接收到请求后，将返回一段 Javascript，在这段  Javascript 代码中调用了约定好的回调函数，并且将数据作为参数进行传递。当网页接收到这段 Javascript 代码后，就会执行这个回调函数，这时数据已经成功传输到客户端了。

  ```java
  <script type="text/javascript">
      function dosomething(jsondata){
          //处理获得的json数据
      }
  </script>
      
  <script src="http://example.com/data.php?callback=dosomething"></script>   
  //dosomething(['a','b','c']);
  ```

* **Nginx反向代理**







<font color='blue' size='4'>**CSRF是什么？**</font>

CSRF（Cross-site request forgery），中文名称：跨站请求伪造。即攻击者盗用了你的身份，以你的名义发送恶意请求

**CSRF原理：**

* 登录受信任网站A，并在本地生成Cookie。

* 不登出A的情况下，访问危险网站B，B网站嵌入有危险代码。

  ```html
  <img src=http://www.mybank.com/Transfer.php?toBankId=11&money=1000>
  ```

  ![image-20211022090025416](https://gitee.com/jobim/blogimage/raw/master/img/20211022090025.png)



**CSRF的防御：**CSRF的防御可以从**服务端和客户端**两方面着手

> 好的博客：[浅谈CSRF攻击方式](https://www.cnblogs.com/hyddd/archive/2009/04/09/1432744.html)

- **同源检测**

* **验证`HTTP Referer`字段**

  在HTTP头中有一个字段叫Referer，记录了该HTTP请求的来源地址

* **CSRF Token**

* **在 HTTP 头中自定义属性并验证**

  这种方法也是使用 token 并进行验证，和上一种方法不同的是，这里并不是把 token 以参数的形式置于 HTTP 请求之中，而是把它放到 HTTP 头中自定义的属性里





**URI和URL的区别？**

URL我们说是叫统一资源定位符，URI我更愿意叫做统一资源标识符。

举个例子：

> 一个人，身份证是他的唯一标识，可以作为统一资源标识符，而地址是为了找到他，所以是统一资源定位符。

**HTTP请求的GET与POST方式的区别?**

- GET在浏览器回退是无害的，而POST会再次提交请求
- GET请求会被浏览器主动cache,而POST不会，除非手动设置
- GET请求只能进行URL编码，而POST支持多种编码
- GET请求参数会被完整保留在浏览器历史记录中，而POST中的参数不会被保留
- GET请求在URL中传送参数是有大小限制的，不能大于2KB,而POST可以说没有
- GET只接受ASCII字符，而POST没有限制
- GET参数直接暴露在URL上，而POST将数据放在request body中



**SSL四次握手过程？描述一下**

[![img](https://img2020.cnblogs.com/blog/1993240/202008/1993240-20200811095748306-466156555.png)](https://img2020.cnblogs.com/blog/1993240/202008/1993240-20200811095748306-466156555.png)

**TSL的三个随机数作用**

其实TSL就是升级后的SSL，在上面介绍的SSL只是因为历史上习惯了SSL这个称呼，所以用的还是比较多。上面我们虽然介绍了SSL的四次握手，但是并没有详细介绍到里面涉及到的参数。这里呢主要涉及以下几个参数

三个随机数：Client random, Server random, Premaster secret

三个秘钥：公钥(public key)，私钥(private key)，对话密钥(session key)

我们的在具体的过程的使用如下：

- ClientHello：客户端生成一个随机数 `random-client`，传到服务器端（Say Hello)
- ServerHello：服务器端生成一个随机数 `random-server`，和着公钥，一起回馈给客户端（I got it)
- 客户端收到的东西原封不动，加上 `premaster secret`（通过 `random-client`、`random-server` 经过一定算法生成的东西），再一次送给服务器端，这次传过去的东西会使用公钥加密
- 服务器端先使用私钥解密，拿到 `premaster secret`，此时客户端和服务器端都拥有了三个要素：`random-client`、`random-server` 和 `premaster secret`
- 此时安全通道已经建立，以后的交流都会校检上面的三个要素通过算法算出的 `session key`

[![img](https://img2020.cnblogs.com/blog/1993240/202009/1993240-20200920101845657-1610703929.png)](https://img2020.cnblogs.com/blog/1993240/202009/1993240-20200920101845657-1610703929.png)

详细一点的可以参考这一篇博文[点击跳转](https://blog.csdn.net/u010983881/article/details/83588326)

**HTTP 1.0，1.1，2.0，3.0的变化历程？**

本问题答案摘抄自（[点击跳转](https://www.cnblogs.com/wupeixuan/p/8642100.html)）进行修改。。

**HTTP/0.9**

HTTP/0.9是第一个版本的HTTP协议，已过时。它的组成极其简单，只允许客户端发送GET这一种请求，且不支持请求头。由于没有协议头，造成了HTTP/0.9协议只支持一种内容，即纯文本。不过网页仍然支持用HTML语言格式化，同时无法插入图片。

HTTP/0.9具有典型的无状态性，每个事务独立进行处理，事务结束时就释放这个连接。由此可见，HTTP协议的无状态特点在其第一个版本0.9中已经成型。一次HTTP/0.9的传输首先要建立一个由客户端到Web服务器的TCP连接，由客户端发起一个请求，然后由Web服务器返回页面内容，然后连接会关闭。如果请求的页面不存在，也不会返回任何错误码。

**HTTP/1.0**

HTTP协议的第二个版本，第一个在通讯中指定版本号的HTTP协议版本，至今仍被广泛采用。相对于HTTP/0.9增加了如下主要特性：

- 请求与响应支持头域
- 响应对象以一个响应状态行开始
- 响应对象不只限于超文本
- 开始支持客户端通过POST方法向Web服务器提交数据，支持GET、HEAD、POST方法
- 支持长连接（但默认还是使用短连接），缓存机制，以及身份认证

**HTTP/1.1**

HTTP协议的第三个版本是HTTP/1.1，是目前使用最广泛的协议版本。HTTP/1.1是目前主流的HTTP协议版本，相对于HTTP/1.0新增了以下内容：

1. 默认为长连接

   HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection：keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。

2. 提供了范围请求功能(宽带优化)

   HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。这是支持文件断点续传的基础。

3. 提供了虚拟主机的功能(HOST域)

   在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。

4. 多了一些缓存处理字段

   HTTP/1.1在1.0的基础上加入了一些cache的新特性，引入了实体标签，一般被称为e-tags，新增更为强大的Cache-Control头。

5. 错误通知的管理

   在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

**HTTP/2.0**

HTTP协议的第四个版本是HTTP/2.0，相对于HTTP/1.1新增了以下内容：

1. 二进制分帧

   HTTP 2.0 的所有帧都采用二进制编码

   - 帧：客户端与服务器通过交换帧来通信，帧是基于这个新协议通信的最小单位。
   - 消息：是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧组成。
   - 流：流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2 … N）；

2. 多路复用

   多路复用允许同时通过单一的HTTP/2.0 连接发起多重的请求-响应消息。有了新的分帧机制后，HTTP/2.0不再依赖多个TCP 连接去处理更多并发的请求。每个数据流都拆分成很多互不依赖的帧，而这些帧可以交错（乱序发送），还可以分优先级。最后再在另一端根据每个帧首部的流标识符把它们重新组合起来。HTTP 2.0 连接都是持久化的，而且客户端与服务器之间也只需要一个连接（每个域名一个连接）即可。

3. 头部压缩

   HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。HTTP/2.0 要求通讯双方各自缓存一份首部字段表，从而避免了重复传输。

4. 请求优先级

   浏览器可以在发现资源时立即分派请求，指定每个流的优先级，让服务器决定最优的响应次序。这样请求就不必排队了，既节省了时间，也最大限度地利用了每个连接。

5. 服务端推送

   服务端推送能把客户端所需要的资源伴随着index.html一起发送到客户端，省去了客户端重复请求的步骤。正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度。

**HTTP/3.0**

在这里需要先说一下2.0有什么缺点，我们才能知道3.0多了什么的改进：

1. 底层基于TCP协议，需要TCP+TLS建立有两个握手的延迟过程

2. TCP的队头阻塞没有彻底解决。这里需要介绍一下，什么是队头阻塞：多个请求是跑在一个TCP管道中的，但是当出现了丢包时，因为TCP为了保证可靠传输，有个特别的“丢包重传”机制，丢失的包必须要等待重新传输确认，HTTP/2出现丢包时，整个 TCP 都要开始等待重传，那么就会阻塞该TCP连接中的所有请求（如下图）。而对于 HTTP/1.1 来说，可以开启多个 TCP 连接，出现这种情况反到只会影响其中一个连接，剩余的 TCP 连接还可以正常传输数据。

   [![img](https://img2020.cnblogs.com/blog/1993240/202009/1993240-20200924112518231-1825707293.png)](https://img2020.cnblogs.com/blog/1993240/202009/1993240-20200924112518231-1825707293.png)

3.0的改进：

1. 使用了基于UDP协议的QUIC协议。并有以下的好处。

2. 实现了快速握手，避免了tcp和ssl重复握手的时延。加快了速度，提升首次打开页面的速度。

3. 集成了TLS加密功能。在具有同样加密功能的情况下，减少了握手锁花费的时延。

4. 多路复用，实现数据的单独传输，彻底解决了TCP中队头阻塞的问题。

   [![img](https://img2020.cnblogs.com/blog/1993240/202009/1993240-20200924112931218-1267044673.png)](https://img2020.cnblogs.com/blog/1993240/202009/1993240-20200924112931218-1267044673.png)

5. 实现了类似TCP的流量控制、传输可靠性的功能。虽然UDP不提供可靠性的传输，但QUIC在UDP的基础之上增加了一层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他一些TCP中存在的特性。

**这里同样有几个问题，为什么我们的3.0要使用UDP可靠来替代我们的TCP链接？UDP是怎么实现可靠传输的呢？**

其实呢，我们在上面也介绍到了。之所以不使用TCP协议，主要是因为TCP协议的握手和我们的TLS的握手重了，增大了我们的时延。而且使用TCP协议的话，还是解决不了我们的一个队头阻塞的问题，因为TCP它是始终要保持我们的面向可靠传输。而我们又不能直接去修改TCP协议，因为它存在的时间太长了，我们如果要去修改它的话，那么付出的代价也是极高的。

而我们也不是纯粹的使用UDP的协议，而是使用了基于UDP协议的QUIC协议。它在UDP协议上增加了许多的功能（在应用层实现），如确认机制、重传机制、窗口确认机制等，很好的解决了可靠传输，安全加密等我们原来支持的功能，并且还解决了我们的原来的队头阻塞等问题，实现既快又可靠的协议。





# 运输层

## TCP相关

* **传输控制协议 TCP**（Transmission Control Protocol）--提供**面向连接**的，**可靠的**数据传输服务。

**TCP报文首部字段：**

> ![image-20210920101815842](https://gitee.com/jobim/blogimage/raw/master/img/20210920101816.png)
>
> ![image-20210920101859942](https://gitee.com/jobim/blogimage/raw/master/img/20210920101900.png)



### TCP的三次握手

>好的博客：
>[TCP的三次握手与四次挥手理解及面试题](https://blog.csdn.net/qq_38950316/article/details/81087809?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-10.baidujs&dist_request_id=1328655.11452.16158846863208287&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-10.baidujs)
>
>[两张动图-彻底明白TCP的三次握手与四次挥手](https://blog.csdn.net/qzcsu/article/details/72861891)



**TCP的三次握手：**
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210317222402957.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDYzMDY1Ng==,size_16,color_FFFFFF,t_70)



**三次握手总结：**

* TCP协议是传输层的一个面向连接的安全可靠的一个传输协议，三次握手的机制是为了保证能建立一个安全可靠的连接。
* TCP服务器进程先创建传输控制块TCB，时刻准备接受客户进程的连接请求，此时服务器就进入了LISTEN（监听）状态；
* 第一次握手是由客户端发起，TCP客户进程也是先创建传输控制块TCB，客户端会向服务端发送一个链接请求报文，在报文里面：SYN标志位置为1，表示发起新的连接。
* 当服务端收到这个报文之后就知道客户端要和我建立一个新的连接，服务端就向客户端发送一个确认消息包，在这个消息包里面：ack标志位置为1，表示确认客户端发起的第一次连接请求。
* 以上两次握手之后，对于客户端而言：已经明确了我既能给服务端成功发消息，也能成功收到服务端的响应。但是对于服务端而言：两次握手是不够的，因为到目前为止，服务端只知道一件事，客户端发给我的消息我能收到，但是我响应给客户端的消息，客户端能不能收到我是不知道的。
* 所以，还需要进行第三次握手，第三次握手就是当客户端收到服务端发送的确认响应报文之后，还要继续去给服务端进行回应，也是一个ack标志位置1的确认消息。通过以上**三次连接，不管是客户端还是服务端，都知道我既能给对方发送消息，也能收到对方的响应。**



<font color='red'>**tcp为什么要三次握手，而不能二次握手？**</font>

* 三次握手是**为了防止当已失效的连接请求报文段突然又传到服务端，造成双方的不一致，导致资源的浪费**
* 当进行第一次握手，网络不好可能会堵塞，所以连接的请求并没有到达服务器端；但是tcp连接有超时重传的机制，所以再一次发送请求，这时候服务器端接收到了你的请求，他也会返回一个请求给你，这是第二次握手；但是这时候网络环境突然又好了起来，那个堵塞的请求到达了服务器端，服务器端又给你回了一个请求，但是你又不想给服务器发送请求，这时候服务器的资源会进行占用等待你的请求，为了不使服务器的资源继续占用，你又必须发送一个请求给服务器



<font color='red'>**如果已经建立了连接，但是客户端突然出现故障了怎么办？**</font>

* TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。



### TCP的四次挥手



**TCP的四次挥手：**
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210317222536902.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDYzMDY1Ng==,size_16,color_FFFFFF,t_70)

**四次挥手总结：**

* **客户端进程发出连接释放报文**，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
* **服务器收到连接释放报文，发出确认报文**，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，**服务端就进入了`CLOSE-WAIT（关闭等待）状态`**。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于**半关闭状态**，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
* 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
* **服务器将最后的数据发送完毕后，就向客户端发送连接释放报文**，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
* **客户端收到服务器的连接释放报文后，必须发出确认**，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，**必须经过2MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。**
* **服务器只要收到了客户端发出的确认，立即进入CLOSED状态**。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。





**<font color='red'>为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？</font>**

* **为了保证客户端发送的最后一个确认，能够达到服务器**
* TIME_WAIT状态就是用来重发可能丢失的ACK报文。**在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段**。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。**如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL**。
* 所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。



### TCP 协议如何保证可靠传输

**1、校验和**

* 发送方在发送数据之前计算检验和，并进行校验和的填充。
* 接收方收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方的进行比对。

**2、确认应答和序列号**

- 序列号：TCP给发送的每一个包进行编号（序列号依次递增），接收方对数据包进行排序，把有序数据传送给应用层。

- 确认应答：TCP传输的过程中，每次**接收方收到数据后，都会对传输方进行确认应答**。也就是发送ACK报文。

  这个ACK报文当中带有对应的**确认序列号**，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。

**3、超时重传**

* 就是发送方在发送完数据后等待一个时间，**时间到达没有接收到ACK报文，那么对刚才发送的数据进行重新发送。**

* 重传时间：TCP采用自适应算法，动态该表重传时间RTTs（加权平均往返时间）

**4、连接管理**

* 即三次握手与四次挥手

**5、流量控制**

* TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。

**6、拥塞控制**

* 当网络拥塞时，可能会造成网络的拥堵，甚至网络瘫痪，TCP会减少数据的发送。



### 说一下ARQ协议？

* ARQ协议，即自动重传请求（Automatic Repeat-reQuest），意思是如果发送方在发送后一段时间之内没有收到确认回执，它通常会重新发送。ARQ协议包括停止等待ARQ协议和连续ARQ协议。

**停止等待ARQ协议：**

* 停止等待ARQ协议是指，在停止等待中如果接收端没有收到发送端发来的分组，接收端就不会给发送端发送确认回执，此时发送端会重新发送之前的报文分组。发送端会维护一个超时计时器，超时时间会设置的比数据在传输往返过程的时间要长一些。

**连续ARQ协议：**

* 连续ARQ协议是指，发送端维护一个“窗口”，“窗口”内可以有多个分组，窗口的大小就是窗口中分组的个数，凡是位于“窗口”内的分组可以连续发送出去而不必等待接收端返回的确认回执，对按序到达的最后一个分组，接收端会向发送端发送确认回执，如果有分组没有正确到达，会返回最后一个正确达到的分组序号，该序号后面的分组会重新发送给接收端。
* 在连续ARQ协议中，发送端会维护一块发送端的数据缓存，“窗口”里的分组都会在这个缓存中，当需要重新发送“窗口”中的分组报文时，便会从缓存里读取分组并发送。
* 连续 ARQ 协议可提高信道利用率。



### TCP流量控制

* TCP 协议通过滑动窗口来实现流量的控制，TCP滑动窗口分为接受窗口，发送窗口。**接收方通过告诉发送方自己的窗口大小**，从而控制发送方的发送速度。
* 接收方在发送确认报文的时候会携带一个接收窗口的参数，发送方根据收到ACK当中的期望收到的下一个字节的序号n以及接收窗口m，还有当前已经发送的字节序号x，算出还可以发送的字节数。



**持续计时器：**

* 只要 TCP 连接的一方收到对方的零窗口通知，就启动该持续计时器。 **若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带 1 字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值**。 若窗口仍然是零，则收到这个报文段的一方就重新设置持续计时器。



### TCP拥塞控制

**拥塞控制是防止过多的数据注入网络，使得网络中的路由器或者链路过载。流量控制是点对点的通信量控制，而拥塞控制是全局的网络流量整体性的控制。发送双方都有一个拥塞窗口（cwnd）。**

* **慢开始**：最开始发送方的拥塞窗口cwnd=1，由小到大递增。每经过一个传输轮次，拥塞窗口cwnd加倍（乘2）。当cwnd超过慢开始门限ssthresh（初始为16），则使用拥塞避免算法，避免cwnd增长过长。
* **拥塞避免（算法）**：当cwnd超过慢开始门限，每经过一个往返时间RTT，cwnd就增长1。在慢开始和拥塞避免过程中，一旦发现网络拥塞，就把慢开始门限设置为当前值的一半（ssthresh = cwnd / 2），并且重新设置cwnd为1，重新慢启动。
* **快重传**：接收方每收到一个失序的报文段后就立即发出重复确认，发送方只要收到**3个重复确认**就立即重传。
* **快恢复**：当发送方连续收到三个重复确认，就将慢开始门限减半，将当前的窗口设置为慢开始门限，并采用拥塞避免算法。（采用快恢复算法时，慢开始只在建立连接和网络超时时才使用）

![image-20210920093219368](https://gitee.com/jobim/blogimage/raw/master/img/20210920093219.png)



### SYN洪泛攻击

> **SYN洪泛攻击发生在三次握手建立TCP连接的过程中，利用三次握手机制，攻击端在第一次握手后就没反应了，导致服务器不断发送ACK确认报文，同时占用了分配的窗口内存资源**

* 攻击者发送TCP的SYN，服务器返回ACK后，该**攻击者就不对其进行确认**，那么这个TCP连接处于挂起状态，所谓的**半连接状态**。
* 服务器收不到再确认的话，还会**重复发送ACK给攻击者**，这样就更加**浪费服务器资源**。
* 攻击者如果发送非常大量的这种TCP连接，由于**每一个都无法完成三次握手**，所以服务器上**这些TCP连接会因为挂起状态而消耗CPU和内存**，最后服务器可能死机，就无法为正常用户提供服务。

解决办法：

1. 第一种是缩短SYN Timeout时间，由于SYN Flood攻击的效果取决于服务器上保持的SYN半连接数，这个值=SYN攻击的频度 x SYN Timeout，所以通过缩短从接收到SYN报文到确定这个报文无效并丢弃改连接的时间，例如设置为20秒以下，可以成倍的降低服务器的负荷。但过低的SYN Timeout设置可能会影响客户的正常访问。

2. 第二种方法是设置SYN Cookie，就是给每一个请求连接的IP地址分配一个Cookie，如果短时间内连续受到某个IP的重复SYN报文，就认定是受到了攻击，并记录地址信息，以后从这个IP地址来的包会被一概丢弃。这样做的结果也可能会影响到正常用户的访问。

## UDP相关

**UDP的首部字段：**

> ![image-20210920091440539](https://gitee.com/jobim/blogimage/raw/master/img/20210920091447.png)





### TCP和UDP的区别

1. TCP**面向连接**（如打电话要先拨号建立连接）;UDP是**无连接的**，即发送数据之前不需要建立连接
2. **TCP提供可靠交付的服务，保证数据的正确性**。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;**UDP尽最大努力交付，即不保证可靠交付**
3. **TCP面向字节流**，实际上是TCP把数据看成一连串无结构的字节流;**UDP是面向报文的** 发送方的UDP对应用程序交下来的报文， 在添加首部后就向下交付给IP层。 
4. **UDP没有拥塞控制**，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）
5. 每一条**TCP连接只能是点到点的**;UDP支持一对一，一对多，多对一和多对多的交互通信
6. TCP首部开销20字节;UDP的首部开销小，只有8个字节
7. TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道





**TCP与UDP的特点和区别？**

**UDP的特点：**

- **UDP是无连接的。**即发送数据之前不需要建立连接，所有也没有连接释放，减少了时延。
- **UDP是尽最大努力交付的。**即不保证可靠交付。
- **UDP是面向报文的。**
- **UDP没有拥塞控制。**因此网络出现的阻塞不会使源主机的发送效率降低。
- **UDP支持一对一、一对多、多对一和多对多的交互通信。**
- **UDP的首部开销小。**只有八个字节，比TCP的20个字节的首部短。

**TCP的特点：**

- **TCP是面向连接的运输层协议。**应用进程之间的通信好像在“打电话”：通话前要先拨号建立连接，通话结束后要挂机释放连接。
- **每一条TCP连接只能有两个端点。**即TCP是点对点连接的。
- **TCP提供可靠交付的服务。**通过TCP连接传送的数据，无差错、不丢失、不重复，并且按序到达。
- **TCP提供全双工通信。**TCP允许通信双方的应用进程在任何时候都能发送数据。
- **TCP面向字节流。**“面向字节流”的含义是虽然应用程序和TCP的交互是一次一个数据块，但TCP把应用程序交下来的数据仅仅看成是一连串的**无结构的字节流。**

**TCP与UDP的区别：**

- UDP是无连接的，即发送数据之前不需要建立连接；TCP是面向连接的运输层协议。
- UDP使用尽最大努力交付，即不保证可靠交付，同时也不使用拥塞控制；TCP提供可靠的交付服务，提供全双工通信。
- UDP支持一对一，一对多，多对一和多对多的交互通信；TCP只能一对一连接。
- UDP首部开销小，只有8个字节；TCP 面向字节流，头部最低20个字节。
- TCP消耗更多的资源，传输速度慢，UDP相对较快，所以一些即时通讯软件使用UDP效果更好。



### 运行在TCP/UDP的相关协议

**运行在TCP协议上的协议：**

* HTTP（Hypertext Transfer Protocol，超文本传输协议）Web服务器传输超文本到本地浏览器的传送协议。端口：80
* HTTPS（HTTP over SSL，安全超文本传输协议）,HTTP协议的安全版本。端口：443
* FTP（File Transfer Protocol，文件传输协议），用于文件传输。端口：21
* SMTP（Simple Mail Transfer Protocol，简单邮件传输协议），用来发送电子邮件。端口：25
* SSH（Secure Shell，用于替代安全性差的TELNET），用于加密安全登陆用。

**运行在UDP协议上的协议：**

* DNS（Domain Name Service，域名服务），用于完成地址查找，邮件转发等工作。
* SNMP（Simple Network Management Protocol，简单网络管理协议），用于网络信息的收集和网络管理。
* NTP（Network Time Protocol，网络时间协议），用于网络同步。
* DHCP（Dynamic Host Configuration Protocol，动态主机配置协议），动态配置IP地址。



# 网络层

网络层的设计思路是：“网络层只向上提供简单灵活的、无连接的、尽最大努力交付的服务。”关于网络层的知识点也很多，但是在面试中的高频知识点不多。

**网络层里网际IP协议是TCP/IP体系中两个最重要的协议之一。**与IP协议配套使用的还有三个协议：

- 地址解析协议ARP（Address Resolution Protocol）
- 网际控制报文协议ICMP（Internet Control Message Protocol）
- 网际组管理协议IGMP（Internet Group Management Protocol）

**IP地址是如何分类的？**

[![img](https://img2020.cnblogs.com/blog/1993240/202008/1993240-20200811095547134-1040088240.png)](https://img2020.cnblogs.com/blog/1993240/202008/1993240-20200811095547134-1040088240.png)

**什么是私有/保留IP地址？**

**私有/保留就是在互联网上不使用，而被使用在局域网络中的地址或者做其他特殊用途。**比如我们的联通运营商就是使用的10.开头的保留地址, 局域网组网，然后用户通过拨号的方式进入局域网，然后再通过访问网关访问Internet，这样做最大的好处就是节约了公网IP地址，极大的降低了成本。

**有哪些私有/保留IP地址？**

A类：10.0.0.0 ~ 10.255.255.255

B类：172.16.0.0 ~ 172.31.255.255

C类：192.168.0.0 ~ 192.168.255.255

**ARP协议是如何解析MAC地址的，什么是ARP欺骗？**

**网络层的 ARP 协议完成了 IP 地址与物理地址的映射。**

首先，每台主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址的对应关系。当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP 列表中是否存在该 IP 地址对应的 MAC 地址：如果有，就直接将数据包发送到这个 MAC 地址；如果没有，就向本地网段发起一个 ARP 请求的广播包，查询此目的主机对应的 MAC 地址。此 ARP 请求数据包里包括源主机的 IP 地址、硬件地址、以及目的主机的 IP 地址。网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址；源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。

ARP默认了其所在的网络是一个善良的网络，每台主机在向网络中发送应答信号时都是使用的真实身份。所以人们就发现ARP应答中的IP地址和MAC地址中的信息是可以伪造的，并不一定是自己的真实IP地址和MAC地址，由此，ARP欺骗就产生了。

**什么是icmp协议，它的作用是什么？**

它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。





